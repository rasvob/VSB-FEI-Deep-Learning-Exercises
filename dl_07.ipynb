{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86f2EBR75Itm",
    "tags": []
   },
   "source": [
    "# Deep Learning - Exercise 7\n",
    "\n",
    "The aim of this exercise is to learn how to build unsupervised word embeddings using the Word2Vec Skip-Gram method and implement recurrent neural networks (RNNs) for text generation using Harry Potter books as our dataset.\n",
    "\n",
    "**Core Concepts**\n",
    "* 🧠 Word2Vec Skip-Gram model for creating word embeddings\n",
    "* 📚 Harry Potter corpus for training word embeddings\n",
    "* 🔤 Analyzing word relationships in embedding space\n",
    "* ⚡ Text generation using character-based RNNs\n",
    "* 📝 Creating Harry Potter style stories with generative models\n",
    "\n",
    "The Word2Vec approach is based on [official Keras tutorial](https://www.tensorflow.org/tutorials/text/word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fi2Jwhs35Itq"
   },
   "source": [
    "[Open in Google colab](https://colab.research.google.com/github/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/dl_07.ipynb)\n",
    "[Download from Github](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/dl_07.ipynb)\n",
    "\n",
    "##### Remember to set **GPU** runtime in Colab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 09:53:44.934617: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-28 09:53:44.944543: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740736424.956149  931301 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740736424.959642  931301 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-28 09:53:44.972352: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.18.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow import string as tf_string\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.layers import LSTM, GRU, Bidirectional\n",
    "\n",
    "from sklearn.model_selection import train_test_split # \n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import scipy\n",
    "import itertools\n",
    "import string\n",
    "import re\n",
    "import tqdm\n",
    "import io\n",
    "\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_history(history):\n",
    "    plt.figure()\n",
    "    for key in history.history.keys():\n",
    "        plt.plot(history.epoch, history.history[key], label=key)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔎 What is word embedding?\n",
    "* Why do we use it? \n",
    "* Do we need to train our own embedding?\n",
    "* Do the embedding have any other usage beside ANN applications?\n",
    "\n",
    "# 📒 Word2Vec\n",
    "\n",
    "## 💡 There are two approaches for a Word2Vec embedding training\n",
    "\n",
    "* **Continuous bag-of-words model**: \n",
    "    * predicts the middle word based on surrounding context words. \n",
    "    * the context consists of a few words before and after the current (middle) word. \n",
    "    * this architecture is called a bag-of-words model as the order of words in the context is not important.\n",
    "\n",
    "* **Continuous skip-gram model**: \n",
    "    * predicts words within a certain range before and after the current word in the same sentence. \n",
    "    * **we will use this as it is easier concept to grasp**\n",
    "\n",
    "![w2v](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_07_skip.png?raw=true)\n",
    "  \n",
    "* 📌 Bag-of-words model predicts a word given the neighboring context\n",
    "* 📌 Skip-gram model predicts the context (or neighbors) of a word, given the word itself\n",
    "\n",
    "* The model is trained on skip-grams, which are n-grams that allow tokens to be skipped (see the diagram below for an example). \n",
    "* 💡 The context of a word can be represented through a set of skip-gram pairs of `(target_word, context_word)` where `context_word` appears in the neighboring context of target_word.\n",
    "\n",
    "## 🔎 What is the difference between Word2Vec or other embeddings and GPT-like models?\n",
    "* The core idea is the same: Both models need a way to represent words as dense vectors in a continuous vector space\n",
    "* The models serve different purposes and operate in different ways\n",
    "    * GPT-like models are focused more on vector-to-vector tasks - generating of text answers\n",
    "        * e.g. question answering, translation, text completion, ....\n",
    "    * Traditional models focus rather on vector-to-scalar tasks - classification\n",
    "        * e.g. sentiment analysis\n",
    "* Word2Vec embeddings generate fixed-size vector representations for words based on their co-occurrence statistics within a context window\n",
    "    * These representations do not capture the context in which the word appears in a specific sentence or document\n",
    "    * 💡 Word2Vec embeddings can be trained on relatively smaller corpora and still capture meaningful semantic relationships between words\n",
    "* GPT models capture contextual understanding by considering the entire preceding context when generating each token in a sequence\n",
    "    * This allows them to generate more contextually relevant responses and understand nuances in language better\n",
    "    * 💡 The model to learn rich representations of language and capture long-range dependencies\n",
    "    * 💡 GPT models need exposure to a diverse range of linguistic patterns and contexts, which typically requires a large dataset\n",
    "* 📌 A \"crossover\" between both approaches are transformer models models like BERT \n",
    "    * It uses a masked language model (MLM) objective, where random words in a sentence are masked, and the model is trained to predict these masked words based on the surrounding context \n",
    "    * Additionally, BERT also uses a next sentence prediction (NSP) objective during pre-training to learn sentence-level relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will demonstrate the Word2Vec working using single sentence\n",
    "\n",
    "* The context words for each of the 8 words of this sentence are defined by a window size. \n",
    "    * 💡 The window size determines the span of words on either side of a target_word that can be considered a context word.\n",
    "\n",
    "![w2v_tab](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_07_tab.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the first step we will tokenize the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The wide road shimmered in the hot sun\"\n",
    "tokens = list(sentence.lower().split())\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can build the vocabulary and mapping WORD -> ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'the': 1, 'wide': 2, 'road': 3, 'shimmered': 4, 'in': 5, 'hot': 6, 'sun': 7}\n"
     ]
    }
   ],
   "source": [
    "vocab, index = {}, 1  # start indexing from 1\n",
    "vocab['<pad>'] = 0  # add a padding token\n",
    "for token in tokens:\n",
    "    if token not in vocab:\n",
    "        vocab[token] = index\n",
    "        index += 1\n",
    "vocab_size = len(vocab)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## It is common to also build also the inverse mapping ID -> WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<pad>', 1: 'the', 2: 'wide', 3: 'road', 4: 'shimmered', 5: 'in', 6: 'hot', 7: 'sun'}\n"
     ]
    }
   ],
   "source": [
    "inverse_vocab = {index: token for token, index in vocab.items()}\n",
    "print(inverse_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So int-encoded sentences will look like this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 1, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "example_sequence = [vocab[word] for word in tokens]\n",
    "print(example_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌 We can use the [tf.keras.preprocessing.sequence.skipgrams](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence) to generate skip-gram pairs\n",
    "\n",
    "*  We will generate skip-grams from the example_sequence with a given window_size from tokens in the range [0, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "      example_sequence,\n",
    "      vocabulary_size=vocab_size,\n",
    "      window_size=window_size,\n",
    "      negative_samples=0,\n",
    "      seed=int(SEED))\n",
    "print(len(positive_skip_grams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ Let's take a look at some skip-gram examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4): (the, shimmered)\n",
      "(4, 1): (shimmered, the)\n",
      "(5, 4): (in, shimmered)\n",
      "(7, 1): (sun, the)\n",
      "(4, 3): (shimmered, road)\n"
     ]
    }
   ],
   "source": [
    "for target, context in positive_skip_grams[:5]:\n",
    "    print(f\"({target}, {context}): ({inverse_vocab[target]}, {inverse_vocab[context]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 📒 Negative sampling for one skip-gram\n",
    "\n",
    "* The skip-gram function returns all positive skip-gram pairs by sliding over a given window span\n",
    "\n",
    "### 💡 But we also need some negative examples to train the model as well\n",
    "\n",
    "## 🔎 How can we generate such samples?\n",
    "* To produce additional skip-gram pairs that would serve as negative samples for training, you need to sample random words from the vocabulary\n",
    "* Use the `tf.random.log_uniform_candidate_sampler` function to sample `num_ns` number of negative samples for a given target word in a window\n",
    "    * 💡 You can call the function on one skip-grams's target word and pass the context word as true class to exclude it from being sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shimmered\n",
      "tf.Tensor([3 0 4 2], shape=(4,), dtype=int64)\n",
      "['road', '<pad>', 'shimmered', 'wide']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740736583.683355  931301 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 909 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:02:00.0, compute capability: 8.9\n",
      "I0000 00:00:1740736583.684787  931301 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21792 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:41:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# Get target and context words for one positive skip-gram.\n",
    "target_word, context_word = positive_skip_grams[0]\n",
    "\n",
    "# Set the number of negative samples per positive context.\n",
    "num_ns = 4\n",
    "\n",
    "context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
    "negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "    true_classes=context_class,  # class that should be sampled as 'positive'\n",
    "    num_true=1,  # each positive skip-gram has 1 positive context class\n",
    "    num_sampled=num_ns,  # number of negative context words to sample\n",
    "    unique=True,  # all the negative samples should be unique\n",
    "    range_max=vocab_size,  # pick index of the samples from [0, vocab_size]\n",
    "    seed=SEED,  # seed for reproducibility\n",
    "    name=\"negative_sampling\"  # name of this operation\n",
    ")\n",
    "print(inverse_vocab[target_word], inverse_vocab[context_word])\n",
    "print(negative_sampling_candidates)\n",
    "print([inverse_vocab[index.numpy()] for index in negative_sampling_candidates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reduce a dimension so you can use concatenation (in the next step).\n",
    "squeezed_context_class = tf.squeeze(context_class, 1)\n",
    "\n",
    "# Concatenate a positive context word with negative sampled words.\n",
    "context = tf.concat([squeezed_context_class, negative_sampling_candidates], 0)\n",
    "\n",
    "# Label the first context word as `1` (positive) followed by `num_ns` `0`s (negative).\n",
    "label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
    "target = target_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_index    : 1\n",
      "target_word     : the\n",
      "context_indices : [4 3 0 4 2]\n",
      "context_words   : ['shimmered', 'road', '<pad>', 'shimmered', 'wide']\n",
      "label           : [1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"target_index    : {target}\")\n",
    "print(f\"target_word     : {inverse_vocab[target_word]}\")\n",
    "print(f\"context_indices : {context}\")\n",
    "print(f\"context_words   : {[inverse_vocab[c.numpy()] for c in context]}\")\n",
    "print(f\"label           : {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The whole process can be illustrated with this example\n",
    "\n",
    "![w2v_example](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_07_example.png?raw=true)\n",
    "\n",
    "## Skip-gram sampling table\n",
    "* A large dataset means larger vocabulary with higher number of more frequent words such as stopwords\n",
    "* 💡 Training examples obtained from sampling commonly occurring words (such as the, is, on) don't add much useful information for the model\n",
    "    * Subsampling of frequent words as a helpful practice to improve embedding quality\n",
    "\n",
    "### `sampling_table[i]` denotes the probability of sampling the `i-th` most common word in a dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00315225 0.00315225 0.00547597 0.00741556 0.00912817 0.01068435\n",
      " 0.01212381 0.01347162 0.01474487 0.0159558 ]\n"
     ]
    }
   ],
   "source": [
    "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=10)\n",
    "print(sampling_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ Compile all the steps described above into a function that can be called on a list of vectorized sentences obtained from any text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generates skip-gram pairs with negative sampling for a list of sequences\n",
    "# (int-encoded sentences) based on window size, number of negative samples\n",
    "# and vocabulary size.\n",
    "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
    "  # Elements of each training example are appended to these lists.\n",
    "    targets, contexts, labels = [], [], []\n",
    "\n",
    "  # Build the sampling table for `vocab_size` tokens.\n",
    "    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "\n",
    "  # Iterate over all sequences (sentences) in the dataset.\n",
    "    for sequence in tqdm.tqdm(sequences):\n",
    "        \n",
    "    # Generate positive skip-gram pairs for a sequence (sentence).\n",
    "        positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "              sequence,\n",
    "              vocabulary_size=vocab_size,\n",
    "              sampling_table=sampling_table,\n",
    "              window_size=window_size,\n",
    "              seed=int(SEED),\n",
    "              negative_samples=0)\n",
    "\n",
    "        # Iterate over each positive skip-gram pair to produce training examples\n",
    "        # with a positive context word and negative samples.\n",
    "        for target_word, context_word in positive_skip_grams:\n",
    "            context_class = tf.expand_dims(tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "            negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "              true_classes=context_class,\n",
    "              num_true=1,\n",
    "              num_sampled=num_ns,\n",
    "              unique=True,\n",
    "              range_max=vocab_size,\n",
    "              seed=int(SEED),\n",
    "              name=\"negative_sampling\")\n",
    "\n",
    "          # Build context and label vectors (for one target word)\n",
    "            context = tf.concat([tf.squeeze(context_class,1), negative_sampling_candidates], 0)\n",
    "            label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
    "\n",
    "          # Append each element from the training example to global lists.\n",
    "            targets.append(target_word)\n",
    "            contexts.append(context)\n",
    "            labels.append(label)\n",
    "\n",
    "    return targets, contexts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📒 Now we can download the Harry Potter and the Sorcerer's Stone book and train our own ombedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('hp1.txt', 'https://raw.githubusercontent.com/rasvob/VSB-FEI-Deep-Learning-Exercises/main/datasets/hp1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First 50 lines of the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Sorcerer's Stone\n",
      "\n",
      "\n",
      "CHAPTER ONE\n",
      "\n",
      "THE BOY WHO LIVED\n",
      "\n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say\n",
      "that they were perfectly normal, thank you very much. They were the last\n",
      "people you'd expect to be involved in anything strange or mysterious,\n",
      "because they just didn't hold with such nonsense.\n",
      "\n",
      "Mr. Dursley was the director of a firm called Grunnings, which made\n",
      "drills. He was a big, beefy man with hardly any neck, although he did\n",
      "have a very large mustache. Mrs. Dursley was thin and blonde and had\n",
      "nearly twice the usual amount of neck, which came in very useful as she\n",
      "spent so much of her time craning over garden fences, spying on the\n",
      "neighbors. The Dursleys had a small son called Dudley and in their\n",
      "opinion there was no finer boy anywhere.\n",
      "\n",
      "The Dursleys had everything they wanted, but they also had a secret, and\n",
      "their greatest fear was that somebody would discover it. They didn't\n",
      "think they could bear it if anyone found out about the Potters. Mrs.\n",
      "Potter was Mrs. Dursley's sister, but they hadn't met for several years;\n",
      "in fact, Mrs. Dursley pretended she didn't have a sister, because her\n",
      "sister and her good-for-nothing husband were as unDursleyish as it was\n",
      "possible to be. The Dursleys shuddered to think what the neighbors would\n",
      "say if the Potters arrived in the street. The Dursleys knew that the\n",
      "Potters had a small son, too, but they had never even seen him. This boy\n",
      "was another good reason for keeping the Potters away; they didn't want\n",
      "Dudley mixing with a child like that.\n",
      "\n",
      "When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story\n",
      "starts, there was nothing about the cloudy sky outside to suggest that\n",
      "strange and mysterious things would soon be happening all over the\n",
      "country. Mr. Dursley hummed as he picked out his most boring tie for\n",
      "work, and Mrs. Dursley gossiped away happily as she wrestled a screaming\n",
      "Dudley into his high chair.\n",
      "\n",
      "None of them noticed a large, tawny owl flutter past the window.\n",
      "\n",
      "At half past eight, Mr. Dursley picked up his briefcase, pecked Mrs.\n",
      "Dursley on the cheek, and tried to kiss Dudley good-bye but missed,\n",
      "because Dudley was now having a tantrum and throwing his cereal at the\n",
      "walls. \"Little tyke,\" chortled Mr. Dursley as he left the house. He got\n",
      "into his car and backed out of number four's drive.\n",
      "\n",
      "It was on the corner of the street that he noticed the first sign of\n",
      "something peculiar -- a cat reading a map. For a second, Mr. Dursley\n",
      "didn't realize what he had seen -- then he jerked his head around to\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file) as f:\n",
    "    lines = f.read().splitlines()\n",
    "for line in lines[:50]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 We will employ the *TextLineDataset* from the TF data API\n",
    "* It allows us to easily load text file line by line and preprocess it\n",
    "* We will skip the book title and blank lines, then we will remove the CHAPTER XYZ lines as the information is not useful\n",
    "    * Then we can transform the text into lowercase and remove the punctuation\n",
    "    * We will use the punctuation from the `re` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"\\\\#\\\\$%\\\\&\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\[\\\\\\\\\\\\]\\\\^_`\\\\{\\\\|\\\\}\\\\~'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.escape(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_ds = tf.data.TextLineDataset(path_to_file).skip(1).filter(lambda x: tf.cast(tf.strings.length(x), bool)).filter(lambda y: not tf.strings.regex_full_match(y, 'CHAPTER.*')).map(lambda z: tf.strings.lower(z)).map(lambda a: tf.strings.regex_replace(a, f'[{re.escape(string.punctuation)}]', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is our pre-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'the boy who lived'\n",
      "b'mr and mrs dursley of number four privet drive were proud to say'\n",
      "b'that they were perfectly normal thank you very much they were the last'\n",
      "b'people youd expect to be involved in anything strange or mysterious'\n",
      "b'because they just didnt hold with such nonsense'\n",
      "b'mr dursley was the director of a firm called grunnings which made'\n",
      "b'drills he was a big beefy man with hardly any neck although he did'\n",
      "b'have a very large mustache mrs dursley was thin and blonde and had'\n",
      "b'nearly twice the usual amount of neck which came in very useful as she'\n",
      "b'spent so much of her time craning over garden fences spying on the'\n"
     ]
    }
   ],
   "source": [
    "for element in text_ds.take(10).as_numpy_iterator():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The TF dataset works as a data stream\n",
    "* 💡 The TF dataset uses standard map/reduce API\n",
    "    * 🔎 How do we iterate over data stream?\n",
    "    * 🔎 How to count elements?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of lines in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int32(7628)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ds.map(lambda x: tf.cast(tf.strings.length(x), tf.int32)).reduce(0, lambda x, y: x + 1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Total length of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int32(405596)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ds.map(lambda x: tf.cast(tf.strings.length(x), tf.int32)).reduce(0, lambda x, y: x + y).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average length of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x795d97b4a340> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x795d97b4a340>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "lambda x: tf.cast(tf.strings.length(x), tf.int32)\n",
      "\n",
      "Match 1:\n",
      "lambda x: tf.cast(tf.strings.length(x), tf.int32)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x795d97b4a340> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x795d97b4a340>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "lambda x: tf.cast(tf.strings.length(x), tf.int32)\n",
      "\n",
      "Match 1:\n",
      "lambda x: tf.cast(tf.strings.length(x), tf.int32)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x795d953002c0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x795d953002c0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "lambda x, y: x + y\n",
      "\n",
      "Match 1:\n",
      "lambda x, y: x + 1\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x795d953002c0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x795d953002c0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "lambda x, y: x + y\n",
      "\n",
      "Match 1:\n",
      "lambda x, y: x + 1\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int32(53)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ds.map(lambda x: tf.cast(tf.strings.length(x), tf.int32)).reduce(0, lambda x, y: x + y).numpy() // text_ds.map(lambda x: tf.cast(tf.strings.length(x), tf.int32)).reduce(0, lambda x, y: x + 1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can setup the `TextVectorization` layer for integer encoding of the tokens\n",
    "* 💡 It is the same layer as in the sentiment analysis excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_length = 15\n",
    "vectorize_layer = keras.layers.TextVectorization(max_tokens=None, output_mode='int', output_sequence_length=sequence_length)\n",
    "vectorize_layer.adapt(text_ds.batch(1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', np.str_('the'), np.str_('and'), np.str_('to'), np.str_('a'), np.str_('he'), np.str_('of'), np.str_('harry'), np.str_('was'), np.str_('it'), np.str_('in'), np.str_('his'), np.str_('you'), np.str_('said'), np.str_('had'), np.str_('i'), np.str_('on'), np.str_('at'), np.str_('that')]\n"
     ]
    }
   ],
   "source": [
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "print(inverse_vocab[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Number of tokens in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6036"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vectorize_layer.get_vocabulary())\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 The `unbatch` works in a similar way as the `ravel` in numpy\n",
    "* i.e. flattening `(n, 1)` shaped array into `(n,)` shaped one\n",
    "    * e.g. `[[5], [0], [2]]` -> `[5, 0, 2]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2  141   74 1071    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "[ 148    3  258  223    7  616  366  646  534   32 1272    4  157    0\n",
      "    0]\n",
      "[  19   20   32 1574  974 1128   13   68  155   20   32    2  143    0\n",
      "    0]\n",
      "[ 131  469  789    4   30 1608   11  165  471  102 1421    0    0    0\n",
      "    0]\n",
      "[ 140   20   63   56  835   24  497 1844    0    0    0    0    0    0\n",
      "    0]\n"
     ]
    }
   ],
   "source": [
    "for x in text_vector_ds.take(5).as_numpy_iterator():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ We can take a look at number of sequences generated and some examples of the data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 09:58:54.835134: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7628"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = list(text_vector_ds.as_numpy_iterator())\n",
    "len(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔎 Why are there the `0` ids?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2  141   74 1071    0    0    0    0    0    0    0    0    0    0\n",
      "    0] => [np.str_('the'), np.str_('boy'), np.str_('who'), np.str_('lived'), '', '', '', '', '', '', '', '', '', '', '']\n",
      "[ 148    3  258  223    7  616  366  646  534   32 1272    4  157    0\n",
      "    0] => [np.str_('mr'), np.str_('and'), np.str_('mrs'), np.str_('dursley'), np.str_('of'), np.str_('number'), np.str_('four'), np.str_('privet'), np.str_('drive'), np.str_('were'), np.str_('proud'), np.str_('to'), np.str_('say'), '', '']\n",
      "[  19   20   32 1574  974 1128   13   68  155   20   32    2  143    0\n",
      "    0] => [np.str_('that'), np.str_('they'), np.str_('were'), np.str_('perfectly'), np.str_('normal'), np.str_('thank'), np.str_('you'), np.str_('very'), np.str_('much'), np.str_('they'), np.str_('were'), np.str_('the'), np.str_('last'), '', '']\n",
      "[ 131  469  789    4   30 1608   11  165  471  102 1421    0    0    0\n",
      "    0] => [np.str_('people'), np.str_('youd'), np.str_('expect'), np.str_('to'), np.str_('be'), np.str_('involved'), np.str_('in'), np.str_('anything'), np.str_('strange'), np.str_('or'), np.str_('mysterious'), '', '', '', '']\n",
      "[ 140   20   63   56  835   24  497 1844    0    0    0    0    0    0\n",
      "    0] => [np.str_('because'), np.str_('they'), np.str_('just'), np.str_('didnt'), np.str_('hold'), np.str_('with'), np.str_('such'), np.str_('nonsense'), '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences[:5]:\n",
    "    print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Finally we can create the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7628/7628 [00:13<00:00, 554.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "targets.shape: (38611,)\n",
      "contexts.shape: (38611, 5)\n",
      "labels.shape: (38611, 5)\n"
     ]
    }
   ],
   "source": [
    "targets, contexts, labels = generate_training_data(\n",
    "    sequences=sequences,\n",
    "    window_size=2,\n",
    "    num_ns=4,\n",
    "    vocab_size=vocab_size,\n",
    "    seed=int(SEED))\n",
    "\n",
    "targets = np.array(targets)\n",
    "contexts = np.array(contexts)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"targets.shape: {targets.shape}\")\n",
    "print(f\"contexts.shape: {contexts.shape}\")\n",
    "print(f\"labels.shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([366, 366, 366, ..., 606,  45, 606])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 534,  373,   10,  631,  168],\n",
       "       [   7,  612,    0,    1, 1509],\n",
       "       [ 616,   72, 1017,  234,    1],\n",
       "       ...,\n",
       "       [  45,    9,   39,   90,   47],\n",
       "       [ 606,    4,   17, 3876,    0],\n",
       "       [  32, 2654,    1,   51, 1825]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will form the dataset using TF data API as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=((TensorSpec(shape=(64, 1), dtype=tf.int64, name=None), TensorSpec(shape=(64, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(64, 5), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets.reshape(-1, 1), contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance tweaks\n",
    "* When the GPU is working on forward / backward propagation on the current batch, we want the CPU to process the next batch of data so that it is immediately ready \n",
    "* 💡 As the most expensive part of the computer, we want the GPU to be fully used all the time during training\n",
    "    * We call this consumer / producer overlap, where the consumer is the GPU and the producer is the CPU\n",
    "\n",
    "* With `tf.data`, you can do this with a simple call to `dataset.prefetch(N)` at the end of the pipeline (after batching). \n",
    "    * 💡 This will always prefetch `N` batches of data and make sure that there is always `N` batches ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 The final step is to define and train the model\n",
    "* We will use 2 `Embedding` layers\n",
    "    * One for the **target word** and one for the **context words**\n",
    "* Finally the dot product of the Embedding outputs will be computed to combine the vectors and the result will be taken as an output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fei/svo0175/Documents/VSB-FEI-Deep-Learning-Exercises/venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ w2v_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">301,800</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ctx_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">301,800</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ w2v_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ ctx_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ w2v_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │    \u001b[38;5;34m301,800\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ctx_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │    \u001b[38;5;34m301,800\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (\u001b[38;5;33mDot\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ w2v_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ ctx_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dot[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">603,600</span> (2.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m603,600\u001b[0m (2.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">603,600</span> (2.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m603,600\u001b[0m (2.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "target_input = keras.layers.Input((1,))\n",
    "context_input = keras.layers.Input((num_ns+1,))\n",
    "\n",
    "emb_w2v = keras.layers.Embedding(vocab_size, embedding_dim, name=\"w2v_embedding\", embeddings_initializer='glorot_uniform', input_length=1)(target_input)\n",
    "emb_ctx = keras.layers.Embedding(vocab_size, embedding_dim, name=\"ctx_embedding\", embeddings_initializer='glorot_uniform', input_length=num_ns+1)(context_input)\n",
    "\n",
    "dots = keras.layers.dot([emb_w2v, emb_ctx], axes=2)\n",
    "\n",
    "fl = keras.layers.Flatten()(dots)\n",
    "\n",
    "# out = keras.layers.Dense(num_ns+1, activation='linear')(fl)\n",
    "\n",
    "model = keras.Model(inputs=[target_input, context_input], outputs=fl)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1740736770.382245  931669 service.cc:148] XLA service 0x7957e80032e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1740736770.382282  931669 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "I0000 00:00:1740736770.382287  931669 service.cc:156]   StreamExecutor device (1): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-02-28 09:59:30.412370: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1740736770.455442  931669 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 86/603\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2188 - loss: 1.6094"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740736770.678852  931669 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2437 - loss: 1.6031\n",
      "Epoch 2/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 0.3884 - loss: 1.4880\n",
      "Epoch 3/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 0.4914 - loss: 1.3534\n",
      "Epoch 4/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 0.6071 - loss: 1.2029\n",
      "Epoch 5/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954us/step - accuracy: 0.6946 - loss: 1.0499\n",
      "Epoch 6/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 955us/step - accuracy: 0.7585 - loss: 0.9060\n",
      "Epoch 7/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 951us/step - accuracy: 0.8087 - loss: 0.7763\n",
      "Epoch 8/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 0.8457 - loss: 0.6624\n",
      "Epoch 9/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 0.8737 - loss: 0.5642\n",
      "Epoch 10/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 0.8952 - loss: 0.4808\n",
      "Epoch 11/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 924us/step - accuracy: 0.9140 - loss: 0.4107\n",
      "Epoch 12/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 0.9280 - loss: 0.3520\n",
      "Epoch 13/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 0.9404 - loss: 0.3030\n",
      "Epoch 14/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 0.9508 - loss: 0.2621\n",
      "Epoch 15/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 0.9598 - loss: 0.2277\n",
      "Epoch 16/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 0.9669 - loss: 0.1989\n",
      "Epoch 17/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - accuracy: 0.9722 - loss: 0.1745\n",
      "Epoch 18/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 0.9760 - loss: 0.1539\n",
      "Epoch 19/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - accuracy: 0.9795 - loss: 0.1363\n",
      "Epoch 20/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 0.9822 - loss: 0.1214\n",
      "Epoch 21/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 0.9837 - loss: 0.1087\n",
      "Epoch 22/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 0.9854 - loss: 0.0978\n",
      "Epoch 23/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 0.9865 - loss: 0.0885\n",
      "Epoch 24/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 0.9874 - loss: 0.0805\n",
      "Epoch 25/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 0.9878 - loss: 0.0737\n",
      "Epoch 26/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 0.9885 - loss: 0.0678\n",
      "Epoch 27/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 0.9892 - loss: 0.0627\n",
      "Epoch 28/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 950us/step - accuracy: 0.9893 - loss: 0.0584\n",
      "Epoch 29/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 0.9894 - loss: 0.0546\n",
      "Epoch 30/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 0.9896 - loss: 0.0514\n",
      "Epoch 31/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917us/step - accuracy: 0.9897 - loss: 0.0486\n",
      "Epoch 32/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.9899 - loss: 0.0462\n",
      "Epoch 33/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 0.9898 - loss: 0.0441\n",
      "Epoch 34/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956us/step - accuracy: 0.9898 - loss: 0.0422\n",
      "Epoch 35/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - accuracy: 0.9899 - loss: 0.0406\n",
      "Epoch 36/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 0.9899 - loss: 0.0393\n",
      "Epoch 37/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - accuracy: 0.9900 - loss: 0.0380\n",
      "Epoch 38/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 0.9899 - loss: 0.0370\n",
      "Epoch 39/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 0.9899 - loss: 0.0361\n",
      "Epoch 40/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.9900 - loss: 0.0353\n",
      "Epoch 41/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.9901 - loss: 0.0345\n",
      "Epoch 42/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.9901 - loss: 0.0339\n",
      "Epoch 43/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - accuracy: 0.9901 - loss: 0.0334\n",
      "Epoch 44/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - accuracy: 0.9902 - loss: 0.0329\n",
      "Epoch 45/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 0.9901 - loss: 0.0324\n",
      "Epoch 46/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939us/step - accuracy: 0.9901 - loss: 0.0321\n",
      "Epoch 47/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - accuracy: 0.9901 - loss: 0.0317\n",
      "Epoch 48/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 0.9901 - loss: 0.0314\n",
      "Epoch 49/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 0.9901 - loss: 0.0311\n",
      "Epoch 50/50\n",
      "\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 924us/step - accuracy: 0.9901 - loss: 0.0309\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ⚡ Now we can save the vectors and visualize it using [TF projector](https://projector.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = model.get_layer('w2v_embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "    if index == 0:\n",
    "        continue  # skip 0, it's padding.\n",
    "    vec = weights[index]\n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "    out_m.write(word + \"\\n\")\n",
    "\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Word2Vec tutorial will be ever complete without the similar word search 🙂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id2word = {k: v for k, v in enumerate(vocab)}\n",
    "word2id = {v: k for k, v in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So here we go, we will search the closest vectors for selected words\n",
    "* 🔎 How is it done?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6036, 6036)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'harry': [np.str_('pearlywhite'),\n",
       "  np.str_('doom'),\n",
       "  np.str_('lamplike'),\n",
       "  np.str_('patted'),\n",
       "  np.str_('crutches')],\n",
       " 'hagrid': [np.str_('touching'),\n",
       "  np.str_('fastened'),\n",
       "  np.str_('sunburn'),\n",
       "  np.str_('poke'),\n",
       "  np.str_('sandy')],\n",
       " 'potter': [np.str_('five'),\n",
       "  np.str_('blinked'),\n",
       "  np.str_('statues'),\n",
       "  np.str_('important'),\n",
       "  np.str_('marge')],\n",
       " 'go': [np.str_('toe'),\n",
       "  np.str_('yet'),\n",
       "  np.str_('make'),\n",
       "  np.str_('dish'),\n",
       "  np.str_('chickened')],\n",
       " 'he': [np.str_('bravo'),\n",
       "  np.str_('glinting'),\n",
       "  np.str_('creeps'),\n",
       "  np.str_('health'),\n",
       "  np.str_('sir')],\n",
       " 'the': [np.str_('such'),\n",
       "  np.str_('arrivals'),\n",
       "  np.str_('presents'),\n",
       "  np.str_('believe'),\n",
       "  np.str_('whippy')],\n",
       " 'one': [np.str_('fleet'),\n",
       "  np.str_('twisting'),\n",
       "  np.str_('traffic'),\n",
       "  np.str_('kind'),\n",
       "  np.str_('subjects')],\n",
       " 'hermione': [np.str_('bending'),\n",
       "  np.str_('boring'),\n",
       "  np.str_('admiring'),\n",
       "  np.str_('west'),\n",
       "  np.str_('kitchens')]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "distance_matrix = cosine_distances(weights)\n",
    "print(distance_matrix.shape)\n",
    "\n",
    "similar_words = {search_term: [id2word[idx] for idx in distance_matrix[word2id[search_term]].argsort()[1:6]] \n",
    "                   for search_term in ['harry', 'hagrid', 'potter', 'go', 'he', 'the', 'one','hermione']}\n",
    "\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The results are clearly far from ideal 😪\n",
    "![w2v_meme_01](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_07_meme_01.png?raw=true)\n",
    "\n",
    "## 🔎 What happend? Did we do anything wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ok, let's try again with pre-trained vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_to_glove_file = 'glove.6B.50d.txt'\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 💡 This is how the embedding latent vector looks like for the word 'audi' and 'bmw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.051355 ,  0.11694  ,  1.0251   ,  0.12414  , -0.83236  ,\n",
       "        1.0288   , -0.64566  , -1.4468   , -0.89265  , -0.32658  ,\n",
       "        0.66507  , -0.65524  , -1.8323   , -1.0347   ,  0.13486  ,\n",
       "       -0.033565 , -0.2208   ,  1.855    , -0.2495   , -0.84343  ,\n",
       "        0.14318  , -0.81258  , -0.84232  ,  1.1247   , -0.075604 ,\n",
       "       -0.30852  , -0.79071  ,  0.80721  , -0.24747  , -0.029263 ,\n",
       "        0.2684   ,  0.6531   ,  0.48872  ,  1.1838   ,  0.5606   ,\n",
       "       -0.68087  ,  0.25192  ,  0.98091  , -1.0433   , -0.27203  ,\n",
       "        1.1912   , -0.88594  ,  0.022038 , -0.82012  , -0.0022396,\n",
       "       -0.68251  ,  0.12713  ,  0.85041  ,  1.002    ,  0.33904  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['audi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.70038 , -0.16073 ,  1.3423  ,  0.63331 , -0.21958 ,  0.31944 ,\n",
       "       -0.67042 , -0.94041 , -0.56935 , -0.67842 ,  0.39705 , -0.18964 ,\n",
       "       -2.2101  , -0.90947 ,  0.95511 , -0.01321 , -0.32738 ,  1.1554  ,\n",
       "       -0.48464 , -1.7606  , -0.051495, -1.0745  , -1.183   ,  0.68672 ,\n",
       "       -0.107   , -0.42152 , -0.15516 ,  0.12724 , -0.42114 ,  0.30905 ,\n",
       "        0.59784 ,  0.050149,  0.24022 ,  0.86494 ,  0.63488 , -0.75644 ,\n",
       "       -0.09189 ,  1.0218  , -0.96638 , -0.90508 ,  0.80575 , -0.75225 ,\n",
       "        0.7642  , -0.94425 ,  0.4609  ,  0.11877 ,  0.24907 ,  0.066667,\n",
       "        0.59622 ,  0.1275  ], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['bmw']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 Hypothesis: The cosine distance of the car brands should be smaller than with some random word\n",
    "* 🔎 Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.16636306)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(embeddings_index['audi'], embeddings_index['bmw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(1.0900573)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(embeddings_index['audi'], embeddings_index['king'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 For trying the famous `queen -> king` example we need to build the embedding matrix\n",
    "\n",
    "![w2v_meme_03](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_07_meme_03.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_tokens = len(embeddings_index.keys())\n",
    "embedding_dim = 50\n",
    "hits = 0\n",
    "misses = 0\n",
    "word2id = {k:i for i, (k,v) in enumerate(embeddings_index.items())}\n",
    "id2word = {v:k for k, v in word2id.items()}\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word2id.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the closest words is pretty easy now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_w = cosine_distances(embedding_matrix[word2id['man']].reshape(-1, 50), embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woman\n",
      "boy\n",
      "another\n",
      "old\n",
      "one\n"
     ]
    }
   ],
   "source": [
    "for x in c_w.argsort().ravel()[1:6]:\n",
    "    print(id2word[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_w = cosine_distances(embedding_matrix[word2id['woman']].reshape(-1, 50), embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl\n",
      "man\n",
      "mother\n",
      "her\n",
      "boy\n"
     ]
    }
   ],
   "source": [
    "for x in c_w.argsort().ravel()[1:6]:\n",
    "    print(id2word[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The idea is that using the difference between `man` and `woman` should be simillar as `king` and `queen`\n",
    "* 💡 Thus it should be possible to use the difference for searching for analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dist = embeddings_index['man'] - embeddings_index['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.087144  , -0.2182    ,  0.40985996,  0.03922001,  0.10320008,\n",
       "       -0.94165003,  0.06042001, -0.32988   , -0.46144   ,  0.35962   ,\n",
       "       -0.31102   ,  0.86824   , -0.96006   , -0.01073003, -0.24337   ,\n",
       "       -0.08193001,  1.02722   ,  0.21122   , -0.695044  ,  0.00222   ,\n",
       "       -0.29106003, -0.50530005,  0.099454  , -0.40445   , -0.30181003,\n",
       "       -0.1355002 ,  0.06060004,  0.07131001,  0.19245   ,  0.06115001,\n",
       "        0.3204    , -0.07165   ,  0.13337001,  0.25068715,  0.14292999,\n",
       "        0.224957  ,  0.14899999, -0.048882  , -0.12191002,  0.27362   ,\n",
       "        0.16547601,  0.20426002, -0.54376   ,  0.27142498,  0.10244995,\n",
       "        0.32108003, -0.2516    ,  0.33454996,  0.04371002, -0.01258   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summed = embeddings_index['queen'] + dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.465684  ,  1.6051    , -0.85494   , -0.06507999,  0.46149006,\n",
       "       -0.34136003, -0.11496   ,  0.50779   , -0.518238  , -0.39833   ,\n",
       "       -0.08420999,  1.85411   , -0.35419   , -0.32492003,  0.04539999,\n",
       "        0.4782    ,  0.25266004,  0.282641  , -1.269144  ,  0.21564001,\n",
       "        0.28568   , -0.11850005, -0.02628601, -0.12433001, -0.02046004,\n",
       "       -1.9408002 , -0.9814999 , -0.12123999, -0.3613    ,  0.00662401,\n",
       "        1.8778    ,  0.32131   , -0.11412999,  0.59319717,  0.59657997,\n",
       "        0.38732702,  0.67364   , -0.119154  , -0.95935005, -0.75898004,\n",
       "        0.624936  ,  0.45728   , -0.72213   , -0.46255502, -0.09780005,\n",
       "        0.55578005, -0.81254995, -1.9493501 ,  0.05298533, -0.61542   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = cosine_distances(summed.reshape(-1, 50), embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And here we go 🙂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king\n",
      "prince\n",
      "crown\n",
      "coronation\n",
      "royal\n"
     ]
    }
   ],
   "source": [
    "for x in res.argsort().ravel()[1:6]:\n",
    "    print(id2word[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![w2v_meme_02](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_07_meme_02.png?raw=true)\n",
    "\n",
    "# We will also learn how to use RNN as a text generator! 🙂\n",
    "* There are two main ways for solving the task\n",
    "    * 💡 Word-based model\n",
    "    * 💡 Character-based model\n",
    "    \n",
    "* We have relatively small dataset thus we will use the **Character-based model** as it works better with smaller datasets\n",
    "    * 💡 We will also simplify the task for using only lower case letters\n",
    "\n",
    "* 🔎 If we would have very large text corpus available, which way would be better and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_hp = tf.data.TextLineDataset(path_to_file).skip(1).filter(lambda x: tf.cast(tf.strings.length(x), bool)).filter(lambda y: not tf.strings.regex_full_match(y, 'CHAPTER.*')).map(lambda z: tf.strings.lower(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "txt_one_line = ''\n",
    "for x in text_hp.as_numpy_iterator():\n",
    "    txt_one_line += str(x)[2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the boy who livedmr. and mrs. dursley, of number four, privet drive, were proud to saythat they were perfectly normal, thank you very much. they were '"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_one_line[:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an array of letters from the whole text and filter out everything which is not lower-case letters and spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "letters = []\n",
    "for x in txt_one_line:\n",
    "    if x >= 'a' and x <= 'z' or x == ' ':\n",
    "        letters.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', ' ', 'b', 'o', 'y', ' ', 'w', 'h']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have corpus of 405551 characters available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405551"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 💡 But only 27 unique tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars: 27\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(letters)))\n",
    "print(\"Total chars:\", len(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will build `ID -> CHAR` and `CHAR -> ID` lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ',\n",
       " 1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z'}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ We need to create fixed length sequences for the model\n",
    "* We will shift the sliding window of `SEQ_LEN` by `step` and for `X,y` pair\n",
    "    * 💡 Input is array of `SEQ_LEN` letters output is just **1** letter which comes after the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 40\n",
    "step = 1\n",
    "X, y = [], []\n",
    "for i in range(0, len(letters) - SEQ_LEN, step):\n",
    "    seq, ch = letters[i:i+SEQ_LEN], letters[i + SEQ_LEN]\n",
    "    X.append(seq)\n",
    "    y.append(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a look at the example\n",
    "* 💡 Focus on the last letter of the second sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', 'h', 'e', ' ', 'b', 'o', 'y', ' ', 'w', 'h', 'o', ' ', 'l', 'i', 'v', 'e', 'd', 'm', 'r', ' ', 'a', 'n', 'd', ' ', 'm', 'r', 's', ' ', 'd', 'u', 'r', 's', 'l', 'e', 'y', ' ', 'o', 'f', ' ', 'n']\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 'e', ' ', 'b', 'o', 'y', ' ', 'w', 'h', 'o', ' ', 'l', 'i', 'v', 'e', 'd', 'm', 'r', ' ', 'a', 'n', 'd', ' ', 'm', 'r', 's', ' ', 'd', 'u', 'r', 's', 'l', 'e', 'y', ' ', 'o', 'f', ' ', 'n', 'u']\n"
     ]
    }
   ],
   "source": [
    "print(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 Characted level RNN uses usually one-hot encoding as we work just with a few unique tokens \n",
    "* So no complex embedding is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_ohe = np.zeros((len(X), SEQ_LEN, len(chars)), dtype=bool)\n",
    "y_ohe = np.zeros((len(X), len(chars)), dtype=bool)\n",
    "for i, sentence in enumerate(X):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X_ohe[i, t, char_indices[char]] = 1\n",
    "    y_ohe[i, char_indices[y[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405511, 40, 27)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405511, 27)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ohe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 The final step is the model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">79,872</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,483</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m27\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m79,872\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)             │         \u001b[38;5;34m3,483\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">280,859</span> (1.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m280,859\u001b[0m (1.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">280,859</span> (1.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m280,859\u001b[0m (1.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_layer = keras.layers.Input(shape=(SEQ_LEN, len(chars)))\n",
    "x = LSTM(128, return_sequences=True)(input_layer)\n",
    "x = LSTM(128, return_sequences=False)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, 'relu')(x)\n",
    "x = keras.layers.Dense(128, 'relu')(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "output_layer = keras.layers.Dense(len(chars), activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(input_layer, output_layer)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss=keras.losses.CategoricalCrossentropy(from_logits=False), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2535/2535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.2488 - loss: 2.5921 - val_accuracy: 0.3968 - val_loss: 2.0201\n",
      "Epoch 2/10\n",
      "\u001b[1m2535/2535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - accuracy: 0.4205 - loss: 1.9438 - val_accuracy: 0.4693 - val_loss: 1.7706\n",
      "Epoch 3/10\n",
      "\u001b[1m2535/2535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.4811 - loss: 1.7324 - val_accuracy: 0.5061 - val_loss: 1.6364\n",
      "Epoch 4/10\n",
      "\u001b[1m2535/2535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - accuracy: 0.5104 - loss: 1.6256 - val_accuracy: 0.5225 - val_loss: 1.5803\n",
      "Epoch 5/10\n",
      "\u001b[1m2535/2535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - accuracy: 0.5293 - loss: 1.5598 - val_accuracy: 0.5355 - val_loss: 1.5496\n",
      "Epoch 6/10\n",
      "\u001b[1m2535/2535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - accuracy: 0.5418 - loss: 1.5172 - val_accuracy: 0.5444 - val_loss: 1.5278\n",
      "Epoch 7/10\n",
      "\u001b[1m2535/2535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.5509 - loss: 1.4873 - val_accuracy: 0.5403 - val_loss: 1.5520\n",
      "Epoch 8/10\n",
      "\u001b[1m2535/2535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.5567 - loss: 1.4684 - val_accuracy: 0.5511 - val_loss: 1.5197\n",
      "Epoch 9/10\n",
      "\u001b[1m2535/2535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.5620 - loss: 1.4496 - val_accuracy: 0.5487 - val_loss: 1.5270\n",
      "Epoch 10/10\n",
      "\u001b[1m2535/2535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.5634 - loss: 1.4432 - val_accuracy: 0.5508 - val_loss: 1.5348\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='best.weights.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(X_ohe, y_ohe, validation_split=0.2, callbacks=[model_checkpoint_callback], epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"best.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [ True, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ohe[0].reshape((1, 40, 27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_ohe[0].reshape((1, 40, 27)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.2556537e-06, 1.2102733e-01, 1.1308529e-06, 1.4314616e-05,\n",
       "       1.6170390e-05, 2.0247650e-01, 6.6902512e-06, 1.7490454e-06,\n",
       "       1.3461773e-03, 1.2410305e-01, 3.2819289e-06, 1.3510156e-07,\n",
       "       2.4752755e-04, 4.1886477e-05, 4.0077633e-05, 4.2724881e-01,\n",
       "       2.2451946e-05, 1.0808331e-05, 7.8866342e-03, 6.7308447e-06,\n",
       "       6.4243686e-06, 1.1320993e-01, 2.3141618e-05, 2.8381607e-04,\n",
       "       9.4277520e-06, 1.9599844e-03, 3.6056110e-06], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌 We won't use output probabilities directly \n",
    "* We will sample from the predicted outputs using Temperature Softmax [see this](https://medium.com/@majid.ghafouri/why-should-we-use-temperature-in-softmax-3709f4e0161)\n",
    "\n",
    "* Basically, the ideas is that it would re-weight the probability distribution so that you can control how much surprising (i.e. higher temperature/entropy) or predictable (i.e. lower temperature/entropy) the next selected character would be\n",
    "    * 💡 The concept of *Temperature* is used among many generative models\n",
    "        * e.g. LLMs like [Mixtral-8x7B](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = sample(y_pred)\n",
    "indices_char[c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 💡 To use the model as a next characted generator for given seed text we need to create a feedback loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_931301/913138547.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  preds = np.log(preds) / temperature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    }
   ],
   "source": [
    "whole_text = X[10].copy()\n",
    "seq = X[10].copy()\n",
    "for i in range(500):\n",
    "    paragraph_ohe = np.zeros((1, SEQ_LEN, len(chars)))\n",
    "    for t, char in enumerate(seq):\n",
    "        paragraph_ohe[0, t, char_indices[char]] = 1\n",
    "    y_pred = model.predict(paragraph_ohe)\n",
    "    c = sample(y_pred[0], 0.5)\n",
    "    next_char = indices_char[c]\n",
    "    whole_text.append(next_char)\n",
    "    seq = whole_text[-SEQ_LEN:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can see that the model has only seen character-level data however it has learnt to generate existing words/phrases \n",
    "* And yes, the output is still far from ideal 🙂\n",
    "* 🔎 How would you make it better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o livedmr and mrs dursley of number four other and harrys and harry had a ron he was around the haw suddenly a his the windows and people that he was a rose the sign in his arrif it had been hagrids the said hagrid harry had to see harry snape seen and harry were a lot of the dursleys said hagrid and said harry the back to the back to a lot the great and hagrid as his he but a show they said harry of the than he was the mead him and hagrid didnt have been his and the the gryffindor so threwhere was before that was and had one a gaspes'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(whole_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✅  Tasks for the lecture\n",
    "* Homework's on vacation mode thanks to the amount of new topics in this lecture, enjoy the break 🙂"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ds4_03.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
