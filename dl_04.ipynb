{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86f2EBR75Itm"
   },
   "source": [
    "# Deep Learning - Exercise 4\n",
    "\n",
    "This lecture is about advanced topics of the CNN such as transfer learning and 1D convolutions for time-series processing.\n",
    "\n",
    "We will use CIFAR-10 dataset again and [FordA](https://www.timeseriesclassification.com/description.php?Dataset=FordA) for time-series classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fi2Jwhs35Itq"
   },
   "source": [
    "[Open in Google colab](https://colab.research.google.com/github/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/dl_04.ipynb)\n",
    "[Download from Github](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/dl_04.ipynb)\n",
    "\n",
    "##### Remember to set **GPU** runtime in Colab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import matplotlib.image as mpimg # images\n",
    "import numpy as np #numpy\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import requests\n",
    "\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "from sklearn.model_selection import train_test_split # split for validation sets\n",
    "from sklearn.preprocessing import normalize # normalization of the matrix\n",
    "from scipy.signal import convolve2d # convolutionof the 2D signals\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_history(history):\n",
    "    plt.figure()\n",
    "    for key in history.history.keys():\n",
    "        plt.plot(history.epoch, history.history[key], label=key)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "def show_example(train_x, train_y, class_names):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(train_x[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(class_names[train_y[i][0]])\n",
    "    plt.show()\n",
    "                \n",
    "def compute_metrics(y_true, y_pred, show_confusion_matrix=False):\n",
    "    print(f'\\tAccuracy: {accuracy_score(y_true, y_pred)*100:8.2f}%')\n",
    "    if (show_confusion_matrix):\n",
    "        print('\\tConfusion matrix:\\n', confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔎 What is *transfer learning* about? 🔎\n",
    "\n",
    "* Transfer learning consists of taking features learned on one problem, and leveraging them on a new, similar problem. \n",
    "    * For instance, features from a model that has learned to identify cars may be useful to kick-start a model meant to identify trucks.\n",
    "        * 🔎 Do you know any famous CNN models?\n",
    "\n",
    "* Transfer learning is usually done for tasks where your dataset has too little data to train a full-scale model from scratch.\n",
    "    * 🔎 How do we benefit from it?\n",
    "    \n",
    "## 📌 Usual pipeline\n",
    "\n",
    "1) Take layers from a previously trained model.\n",
    "\n",
    "2) Freeze them, so you avoid destroying any of the information they contain during future training rounds.\n",
    "\n",
    "3) Add some new, trainable layers, on top of the frozen layers. \n",
    "    * 💡 They will learn how to turn the features extracted by pre-trained layers into predictions on a new dataset.\n",
    "\n",
    "4) Train the new layers using your dataset.\n",
    "\n",
    "* 💡 Optional step: Fine-tuning (= unfreezing the entire model you obtained above, or part of it), and re-training it on the new data with a very **low** learning rate. \n",
    "    * This can potentially achieve meaningful improvements, by incrementally adapting the pretrained features to the new data.\n",
    "    * 🔎 Why do we use **low** learning rate?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6HHl9Cb5IuB"
   },
   "source": [
    "# 🚀 Let's start!\n",
    "\n",
    "## Import dataset **CIFAR10** again\n",
    "* I think (or hope 😀) that you remember most of these detailes from the previous lecture 🙂\n",
    "    * The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes. \n",
    "    * The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. \n",
    "    * There are 6,000 images of each class.\n",
    "\n",
    "## We will resize the images into (224, 224) shape because we will use ResNet50 later and we will also one-hot encode our labels\n",
    "* 💡 If you do not encode the labels you will run into shape mismatch error which is hard to debug - trust me, I've been there 🙂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar is the basic dataset for image classifaction\n",
    "dataset = tf.keras.datasets.cifar10\n",
    "img_size = 224\n",
    "subset = 1000\n",
    "test_size = 0.2\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "class_count = len(class_names)\n",
    "\n",
    "# data from any dataset are loaded using the load_Data function\n",
    "(train_x, train_y), (test_x, test_y) = dataset.load_data()\n",
    "\n",
    "train_y = tf.keras.utils.to_categorical(train_y[:subset], class_count)\n",
    "test_y = tf.keras.utils.to_categorical(test_y[:subset], class_count)\n",
    "\n",
    "train_x_resized = tf.image.resize(train_x[:subset], [img_size, img_size], )\n",
    "test_x_resized = tf.image.resize(test_x[:subset], [img_size, img_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_example(train_x, np.argmax(train_y, axis=1).reshape(-1, 1), class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate a `ResNet50` model with pre-trained weights.\n",
    "* 🔎 What the **include_top** do?\n",
    "* What means **weights='imagenet'** parameter? \n",
    "    * 🔎 Do we need it? \n",
    "    * 🔎 What happens if we use random weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = ResNet50(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(img_size, img_size, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier part at the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 📌 IMPORTANT: Freeze the base model 📌\n",
    "* We don't want to train the encoder path of model yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚡ Create a model input and output layers and interconnect all the parts together\n",
    "* 💡 We make sure that the base_model is running in inference mode here, by passing `training=False`.\n",
    "\n",
    "## 📌 Notes about BatchNormalization layer\n",
    "* Many image models contain **BatchNormalization** layers. \n",
    "* Here are a few things to keep in mind:\n",
    "    * BatchNormalization contains 2 non-trainable weights that get updated during training. \n",
    "        * These are the variables **tracking the mean and variance of the inputs**.\n",
    "* 💡 When you **unfreeze** a model that contains BatchNormalization layers in order to do **fine-tuning**, you should **keep the BatchNormalization layers in inference mode by passing training=False** when calling the base model. \n",
    "    * **Otherwise the updates applied to the non-trainable weights will suddenly destroy what the model has learned.**\n",
    "\n",
    "\n",
    "* 🔎 What the **GlobalAveragePooling2D** layer does?\n",
    "    * After convolutional operations, *tf.keras.layers.Flatten* will reshape a tensor into (n_samples, height*width*channels), for example turning (16, 28, 28, 3) into (16, 2352)\n",
    "    * *GlobalAveragePooling* layer is an alternative to this because it averages all the values according to the last axis. \n",
    "        * This means that the resulting shape will be (n_samples, last_axis). \n",
    "        * 💡 For instance, if your last convolutional layer had 64 filters, it would turn (16, 7, 7, 64) into (16, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📌 Make sure that you call the `preprocess_input` function\n",
    "* Each Keras Application expects a specific kind of input preprocessing. \n",
    "* For ResNet, call `tf.keras.applications.resnet.preprocess_input` on your inputs before passing them to the model.\n",
    "    * 💡 It will convert the input images from RGB to BGR, then will zero-center each color channel with respect to the ImageNet dataset, without scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(img_size, img_size, 3), dtype=tf.uint8)\n",
    "x = tf.cast(inputs, tf.float32)\n",
    "x = tf.keras.applications.resnet50.preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = keras.layers.Dense(class_count, activation='softmax')(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model and check number of parameters\n",
    "* Why do we have only **20,490** trainable parameters?\n",
    "* Why do we use `CategoricalAccuracy` and `CategoricalCrossentropy`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Meme01](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_meme_tf_01.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 Always check if all the shapes match the pre-defined ranges! \n",
    "* Otherwise you will run into shape missmatch issue in the training loop and it is harder to debug than the C++ templates 😅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x_resized.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_x_resized.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUzeNn2JjdML",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights.best.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_x_resized, train_y, validation_split=0.2, batch_size=32, epochs=10, callbacks=[model_checkpoint_callback])\n",
    "\n",
    "show_history(history)\n",
    "\n",
    "# Load best setup\n",
    "model.load_weights(\"weights.best.hdf5\")\n",
    "test_loss, test_acc = model.evaluate(test_x_resized, test_y)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 Fine-tuning\n",
    "* Once your model has converged on the new data, you can try to unfreeze all or part of the base model and retrain the whole model end-to-end with a very low learning rate.\n",
    "    * 💡 It could also potentially lead to quick overfitting -- keep that in mind.\n",
    "* It is critical to only do this step **after the model with frozen layers has been trained to convergence**. \n",
    "    * 💡 If you mix randomly-initialized trainable layers with trainable layers that hold pre-trained features the randomly-initialized layers will cause very large gradient updates during training, \n",
    "    * This will **destroy your pre-trained features**.\n",
    "    \n",
    "### It's also critical to use a *very low learning rate* at this stage, \n",
    "* You are training a much larger model than in the first round of training, on a dataset that is typically very small. \n",
    "    * 💡 As a result, you are at **risk of overfitting** very quickly if you apply large weight updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreeze the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 Recompile your model after you make any changes\n",
    "* The `trainable` attribute of any inner layer is taken into account after re-compilation\n",
    "\n",
    "* Calling `compile()` on a model is meant to \"freeze\" the behavior of that model. \n",
    "    * This implies that the trainable attribute values at the time the model is compiled should be preserved throughout the lifetime of that model, until compile is called again. \n",
    "    * Hence, if you change any trainable value, make sure to call `compile()` again on your model for your changes to be taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-5),\n",
    "              loss=keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUzeNn2JjdML",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights.best.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_x_resized, train_y, validation_split=0.2, batch_size=32, epochs=10, callbacks=[model_checkpoint_callback])\n",
    "\n",
    "show_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best setup\n",
    "model.load_weights(\"weights.best.hdf5\")\n",
    "test_loss, test_acc = model.evaluate(test_x_resized, test_y)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now you are an absolute expert on CNN applications in the image classification tasks 👏 \n",
    "\n",
    "## We can switch to time series processing part of the lecture! 🙂\n",
    "* 🔎What tasks can you imagine for time series processing?\n",
    "* We will use CNN again, but now in Conv1D variant\n",
    "    * 🔎 What is the difference among the 1 - 3D Conv?\n",
    "\n",
    "### There is definitely a cool mathematical expression for each conv layer type however I would like you to understand the topic so we will use the diagrams below 🙂\n",
    "\n",
    "![Meme02](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_meme_tf_02.png?raw=true)\n",
    "\n",
    "### 📒 Conv2D\n",
    "* Conv2D is generally used on Image data. \n",
    "* It is called 2 dimensional CNN because the kernel slides along 2 dimensions on the data as shown in the following image.\n",
    "\n",
    "![Conv2D](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_04_conv2d.png?raw=true)\n",
    "\n",
    "\n",
    "### 📒 Conv1D\n",
    "* Following plot illustrate how the kernel will move on accelerometer data. \n",
    "* Each row represents time series acceleration for some axis. \n",
    "    * The kernel can only move in one dimension along the axis of time.\n",
    "\n",
    "![Conv1D](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_04_conv1d.png?raw=true)\n",
    "\n",
    "# 📌 Summary\n",
    "* In 1D CNN, kernel moves in 1 direction. Input and output data of 1D CNN is 2 dimensional. Mostly used on Time-Series data.\n",
    "* In 2D CNN, kernel moves in 2 directions. Input and output data of 2D CNN is 3 dimensional. Mostly used on Image data.\n",
    "* In 3D CNN, kernel moves in 3 directions. Input and output data of 3D CNN is 4 dimensional. Mostly used on 3D Image data (MRI, Video).\n",
    "    * 💡 You can check https://towardsdatascience.com/understanding-1d-and-3d-convolution-neural-network-keras-9d8f76e29610 for more details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the FordA data\n",
    "\n",
    "* Let's download [FordA](https://www.timeseriesclassification.com/description.php?Dataset=FordA) dataset converted for our purposes to the [Feather file format](https://arrow.apache.org/docs/python/feather.html), a binary file format for data exchange.\n",
    "\n",
    "* 💡 The classification problem is to diagnose whether a certain symptom exists or does not exist in an automotive subsystem.\n",
    "    * Each case consists of 500 measurements of engine noise and a classification.\n",
    "\n",
    "* 💡 The data originates from ARFF file format used in Weka Data analysis tool and has classes labeled $\\{-1,1\\}$ \n",
    "    * We will convert it to the $\\{0,1\\}$ set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_feather('https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/raw/main/datasets/FordA_TRAIN.feather')\n",
    "test = pd.read_feather('https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/raw/main/datasets/FordA_TEST.feather')\n",
    "train.target.replace({-1:0}, inplace=True)\n",
    "test.target.replace({-1:0}, inplace=True)\n",
    "print('Train: ',train.shape)\n",
    "print('Test: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ We can take a look at the data\n",
    "* The data contain 500 time steps of a measurement and single target value. \n",
    "* The time series is almost normalized and it is not necessary to deal with it using scaling or normalizing. \n",
    "    * It may slightly improve the results but it depends on your experiments. \n",
    "\n",
    "### 🔎 What would you do if the time-series was continual sequence?\n",
    "* How to preprocesss such data and feed it into ANN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colors = ['b', 'g']\n",
    "plt.figure(figsize=(21,9))\n",
    "for idx in range(10):\n",
    "  plt.plot(train.iloc[idx][:-1], c=colors[int(train.iloc[idx][-1])])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.groupby('target').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.groupby('target').std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the labels balance\n",
    "* 🔎 Which metrics can we use? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the data into numpy arrays and separates *X* and *y* data from each other for training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x, train_y = train.drop(columns=['target']).values, train.target.values\n",
    "test_x, test_y = test.drop(columns=['target']).values, test.target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ Create a baseline model\n",
    "* Lets try some simple basic model on the data. DecisionTree and RandomForrest. \n",
    "    * As you will see it is a difficult task for them to get high accuracy results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_models = [DecisionTreeClassifier(random_state=13), RandomForestClassifier(random_state=13)]\n",
    "\n",
    "for model in base_models:\n",
    "    model.fit(train_x, train_y)\n",
    "    y_pred = model.predict(test_x)\n",
    "    print(type(model).__name__)\n",
    "    compute_metrics(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fully connected ANN model\n",
    "* Let's try some basic neural network model for this task. \n",
    "    * It is a typical Dense network with two hidden layers and dropout optimization - it should be able to beat the Randomforrest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, activation='relu', input_shape=train_x[0].shape),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss = keras.losses.BinaryCrossentropy(from_logits=False), metrics = keras.metrics.BinaryAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUzeNn2JjdML",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights.best.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_x, train_y, validation_split=0.2, epochs=10, batch_size=32, callbacks=[model_checkpoint_callback])\n",
    "show_history(history)\n",
    "\n",
    "model.load_weights(\"weights.best.hdf5\")\n",
    "test_loss, test_acc = model.evaluate(test_x, test_y)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 Now we will finally use the CNN! 🙂\n",
    "* To use convolution in single dimension we need to reshape the data to have the proper format. \n",
    "    * The format is the same as for RNN and must be in a format $(number\\_of\\_vectors, vector\\_length,number\\_of\\_dimensions)$\n",
    "        * Given the user experience for the time series analysis tasks in Tensorflow, sharing the same format among CNN and RNN must've been an accident 😅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_xc = np.reshape(train_x, (*train_x.shape, 1))\n",
    "test_xc = np.reshape(test_x, (*test_x.shape, 1))\n",
    "train_xc.shape, test_xc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try the single convolution layer as a input mapping \n",
    "* It generates a huge number of weights for Dense layers after flattening\n",
    "\n",
    "* The results are far from excelent\n",
    "    * 🔎 Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv1D(64, kernel_size=3, activation='relu', input_shape=train_xc[0].shape),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss = keras.losses.BinaryCrossentropy(from_logits=False), metrics = keras.metrics.BinaryAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUzeNn2JjdML",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights.best.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_x, train_y, validation_split=0.2, epochs=10, batch_size=32, callbacks=[model_checkpoint_callback])\n",
    "show_history(history)\n",
    "\n",
    "model.load_weights(\"weights.best.hdf5\")\n",
    "test_loss, test_acc = model.evaluate(test_x, test_y)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A slightly more complicated model is able to beat all previous models with smaller number of weights needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv1D(64, kernel_size=3, activation='relu', input_shape=train_xc[0].shape),\n",
    "    keras.layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    keras.layers.MaxPool1D(2),\n",
    "    keras.layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    keras.layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss = keras.losses.BinaryCrossentropy(from_logits=False), metrics = keras.metrics.BinaryAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUzeNn2JjdML",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights.best.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_x, train_y, validation_split=0.2, epochs=10, batch_size=32, callbacks=[model_checkpoint_callback])\n",
    "show_history(history)\n",
    "\n",
    "model.load_weights(\"weights.best.hdf5\")\n",
    "test_loss, test_acc = model.evaluate(test_x, test_y)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even more capable model with more pooling layers but with 1/4 weight of the previsou model is able to achieve more than 90% of the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv1D(64, kernel_size=3, activation='relu', input_shape=train_xc[0].shape),\n",
    "    keras.layers.MaxPool1D(2),\n",
    "    keras.layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    keras.layers.MaxPool1D(2),\n",
    "    keras.layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    keras.layers.MaxPool1D(2),\n",
    "    keras.layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss = keras.losses.BinaryCrossentropy(from_logits=False), metrics = keras.metrics.BinaryAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUzeNn2JjdML",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights.best.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_x, train_y, validation_split=0.2, epochs=10, batch_size=32, callbacks=[model_checkpoint_callback])\n",
    "show_history(history)\n",
    "\n",
    "model.load_weights(\"weights.best.hdf5\")\n",
    "test_loss, test_acc = model.evaluate(test_x, test_y)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "myIgGem85IvT",
    "tags": []
   },
   "source": [
    "# ✅  Tasks for the lecture (2p)\n",
    "\n",
    "1) Choose any of the models from [Keras pre-trained models](https://keras.io/api/applications/) - **(1p)**\n",
    "\n",
    "    * Investigate its' architecture\n",
    "    * Search for the needed input shape for the model - remeber to preprocess the data and call correct `preprocess_input` function\n",
    "        * 💡 There could be more variants of the model, the choice depends on you\n",
    "    * Use the selected model for CIFAR-10 classification, \n",
    "        * Fine-tune it, experiment with it and write down your conclusions!\n",
    "    \n",
    "2) Define your own model for the FordA data task  - **(1p)**\n",
    "\n",
    "    * Try to beat defined models or have at least the same accuracy score\n",
    "        * 💡 You can also try to minimize the number of parameters for having approx. the same accuracy as we do!\n",
    "    * Experiment with the model and write down your conclusions!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ds4_03.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
